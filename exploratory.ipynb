{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import nltk\n",
    "import cleantext\n",
    "# nltk.download(['stopwords', 'punkt', 'averaged_perceptron_tagger', 'wordnet'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import lxml\n",
    "import html5lib\n",
    "from bs4 import BeautifulSoup\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('results.csv', sep=\",\", low_memory=False)\n",
    "data.head()"
   ],
   "id": "bd0a271816788f1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "data.columns = data.columns.str.lower()",
   "id": "2c9836498054dda0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sns.displot(data=data.isna().melt(value_name=\"missing\"),\n",
    "            y=\"variable\",\n",
    "            hue=\"missing\",\n",
    "            multiple=\"fill\",\n",
    "            aspect=3.25,\n",
    "            )\n",
    "plt.gcf().set_size_inches(8, 15)"
   ],
   "id": "f424d3c796dfe5d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "data['favoritecount'] = data['favoritecount'].fillna(0.0)",
   "id": "1456feed886eddc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "df = data[['id','title','body','tags']]\n",
    "df['tags'] = df['tags'].str.replace('<', '').str.replace('>', ' ').str.split()\n",
    "df_new = df[['id','tags']]\n",
    "df_new.head()"
   ],
   "id": "5b04f649a91c220d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "tags = df_new.explode('tags').reset_index(drop=True)\n",
    "unique_tags = tags['tags'].unique().tolist()\n",
    "# len(unique_tags) 14677\n",
    "unique_tags"
   ],
   "id": "14fdb31438f2a4c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "common_tags = collections.Counter(list(tags['tags'])).most_common(10)\n",
    "common_tags"
   ],
   "id": "a1292790f3f04fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sample_df = df.sample(n=200, replace=True, random_state=1)\n",
    "sample_df = sample_df.reset_index(drop=True)"
   ],
   "id": "fd89d05759f20c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sample_df['post'] = sample_df.apply(lambda x: x['title'] + ' ' + x['body'] if x['title'] == x['title'] else x['body'], axis=1)\n",
    "corpus = sample_df['post'].to_list()\n",
    "tags = sample_df['tags'].to_list()\n",
    "sample_df"
   ],
   "id": "a01ef2b67a35d9c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_html(text):\n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "\n",
    "    for sent in soup(['style', 'script']):\n",
    "            sent.decompose()\n",
    "   \n",
    "        \n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "corpus_wo_html = [clean_html(text) for text in corpus]\n",
    "corpus_wo_html[0]"
   ],
   "id": "5fd0221816972a2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# cleaned_corpus = [cleantext.clean(text, extra_spaces=True, lowercase=True, numbers=True, punct=True, stp_lang='english', stopwords=True) for text in corpus_wo_html]\n",
    "# cleaned_corpus[0]"
   ],
   "id": "c703da944cf2d556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def text_cleaning(text):\n",
    "    \"\"\"\n",
    "    Remove figures, punctuation, words shorter than two letters (excepted C or R) in a lowered text. \n",
    "    \n",
    "    Args:\n",
    "        text(String): Row text to clean\n",
    "        \n",
    "    Returns:\n",
    "       res(string): Cleaned text\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    pattern = re.compile(r'[^\\w]|[\\d_]')\n",
    "    \n",
    "    try: \n",
    "        res = re.sub(pattern,\" \", text).lower()\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = res.split(\" \")\n",
    "    res = list(filter(lambda x: len(x)>3 , res))\n",
    "    res = \" \".join(res)\n",
    "    return res\n",
    "\n",
    "cleaned_corpus = [text_cleaning(text) for text in corpus_wo_html]\n",
    "cleaned_tags = [text_cleaning(text) for text in tags]\n",
    "# cleaned_tags = [cleantext.clean_words(text, punct=True, stp_lang='english') for text in tags]\n",
    "cleaned_tags[0]"
   ],
   "id": "bde74ac6e7f92f1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "cleaned_corpus[0]",
   "id": "43e26e0b30c2ae7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize words of a text.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        text(String): Row text\n",
    "        \n",
    "    Returns\n",
    "    \n",
    "        res(list): Tokenized string.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    try:\n",
    "        res = word_tokenize(text, language='english')\n",
    "    except TypeError:\n",
    "        return text\n",
    "    \n",
    "    res = [token for token in res if token not in stop_words]\n",
    "    return res\n",
    "\n",
    "tokenized_corpus = [tokenize(text) for text in cleaned_corpus]\n",
    "tokenized_tags = [tokenize(text) for text in tags]\n",
    "\n",
    "print(\"Premier élément de la liste tokenized_corpus\\n\")\n",
    "display(tokenized_corpus[0])\n",
    "print(\"\\n\")\n",
    "print(f\"Longueur du premier éléments de liste tokenized_corpus: {len(tokenized_corpus[0])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Premier élément de la liste tokenized_tags\\n\")\n",
    "display(tokenized_tags[0])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(f\"Occurences dans le corpus tokenizé: {len(tokenized_corpus)}\")\n",
    "print(f\"Occurences dans la liste des tags: {len(tokenized_tags)}\")"
   ],
   "id": "3d1f9362f32c66d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time \n",
    "def filtering_nouns(tokens):\n",
    "    \"\"\"\n",
    "    Filter singular nouns\n",
    "    \n",
    "    Args:\n",
    "        tokens(list): A list o tokens\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "        res(list): Filtered token list\n",
    "    \"\"\" \n",
    "    \n",
    "    import nltk\n",
    "    \n",
    "    res = nltk.pos_tag(tokens)\n",
    "    \n",
    "    res = [token[0] for token in res if token[1] == 'NN']\n",
    "    \n",
    "    return res\n",
    "\n",
    "noun_corpus = [filtering_nouns(tokens) for tokens in tokenized_corpus]\n",
    "\n",
    "\n",
    "display(noun_corpus[0])\n",
    "\n",
    "noun_corpus"
   ],
   "id": "a96eac0bc4cf4db6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "def lemmatization(tokens):\n",
    "    \"\"\"\n",
    "    Transform tokens into lems \n",
    "    \n",
    "    Args:\n",
    "        tokens(list): List of tokens\n",
    "        \n",
    "    Returns:\n",
    "        lemmatized(list): List of lemmatized tokens\n",
    "    \"\"\"\n",
    "    import nltk\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        lemmatized.append(lemmatizer.lemmatize(token))\n",
    "        \n",
    "    return lemmatized\n",
    "\n",
    "lemmatized_corpus = [lemmatization(tokens) for tokens in noun_corpus]\n",
    "lemmatized_tags = [lemmatization(tokens) for tokens in tokenized_tags]\n",
    "\n",
    "tags_wo_blanks = []\n",
    "for tokens in lemmatized_tags:\n",
    "    tokens = [token for token in tokens if len(token)>1]\n",
    "    tags_wo_blanks.append(tokens)\n",
    "\n",
    "print(\"Premier élément de la liste lemmatized_corpus\\n\")\n",
    "display(lemmatized_corpus[0])\n",
    "\n",
    "print(\"Premier élément de la liste lemmatized_tags\\n\")\n",
    "display(tags_wo_blanks[0])\n"
   ],
   "id": "75d7ae7ad8c8f013",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Observations restante du corpus original: {sample_df.shape[0]}\")\n",
    "\n",
    "joined_corpus = [\" \".join(text) for text in lemmatized_corpus]\n",
    "corpus_df = pd.DataFrame(joined_corpus, columns=['preprocessed_text'])\n",
    "corpus_df['len_text'] = corpus_df['preprocessed_text'].apply(lambda x: len(x))\n",
    "\n",
    "joined_tags = [\" \".join(tags) for tags in tags_wo_blanks]\n",
    "tag_df = pd.DataFrame(joined_tags, columns=['preprocessed_tags'])\n",
    "tag_df['len_tags'] = tag_df['preprocessed_tags'].apply(lambda x: len(x))\n",
    "# \n",
    "corpus_tag_df = pd.concat([corpus_df, tag_df], axis=1)\n",
    "# \n",
    "empty_data_idx = corpus_tag_df[(corpus_tag_df['len_text']==0) | (corpus_tag_df['len_tags']==0)].index\n",
    "\n",
    "corpus_tag_df.drop(index=empty_data_idx, inplace=True)\n",
    "\n",
    "sample_df.drop(index=empty_data_idx, inplace=True)\n",
    "# \n",
    "print(f\"observations restante du corpus traité: {corpus_tag_df.shape[0]}\")\n",
    "# \n",
    "corpus_tag_df['splitted_text'] = corpus_tag_df['preprocessed_text'].apply(lambda x: x.split(' ') )\n",
    "corpus_tag_df['splitted_tags'] = corpus_tag_df['preprocessed_tags'].apply(lambda x: x.split(' ') )\n",
    "# \n",
    "filtered_corpus = corpus_tag_df['splitted_text'].to_list()\n",
    "filtered_tags = corpus_tag_df['splitted_tags'].to_list()\n",
    "\n",
    "filtered_original_posts = sample_df['post'].to_list()\n",
    "\n",
    "filtered_tokenized_vs_original = pd.concat([sample_df['post'],\n",
    "                                            corpus_tag_df['splitted_text'], \n",
    "                                            corpus_tag_df['splitted_tags']],\n",
    "                                            axis=1)\n",
    "\n",
    "filtered_tokenized_vs_original.to_csv(\"./cleaned_corpus.csv\", index=False)\n",
    "filtered_tokenized_vs_original.to_pickle('./cleaned_corpus.pkl')\n",
    "\n",
    "filtered_tokenized_vs_original.head(10)"
   ],
   "id": "de768a7e02a03136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "def build_word_distribution(corpus):\n",
    "    \"\"\"\n",
    "    Build corpus word distribution\n",
    "    \n",
    "    Args:\n",
    "        Corpus(List of lists): Original corpus\n",
    "    \n",
    "    Returns:\n",
    "        \n",
    "        word_dist_df(DataFrame): Word distribution of the corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    from nltk import FreqDist\n",
    "    word_corpus = [token for token_list in corpus for token in token_list]\n",
    "    word_dist = FreqDist(word_corpus)\n",
    "    word_dist_df = pd.DataFrame(word_dist.items(), columns=['Word', 'Frequency']).set_index('Word')\n",
    "    word_dist_df.sort_values(\"Frequency\", ascending=False, inplace=True)\n",
    "\n",
    "    return word_dist_df\n",
    "\n",
    "word_dist = build_word_distribution(filtered_corpus)\n",
    "\n",
    "print(f\"Nombre de tokens du corpus {word_dist.shape[0]}\")\n",
    "print(\"Affichage des 20 tokens les plus utilisés\")\n",
    "display(word_dist.head(20))"
   ],
   "id": "12d9acfcaa2608e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "tag_dist = build_word_distribution(filtered_tags)\n",
    "print(\"Top 20 des tags les plus utilisés\")\n",
    "display(tag_dist.head(20))\n",
    "print(f\"Nombre de tags: {len(tag_dist)}\")\n",
    "first_200_tags = tag_dist[0:200].index.to_list()"
   ],
   "id": "a172b667bce139cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Observations restantes dans le corpus original: {data.shape[0]}\")\n",
    "filtered_corpus_tag_df = corpus_tag_df.copy()\n",
    "filtered_corpus_tag_df['tags_in_top200'] = filtered_corpus_tag_df['splitted_tags'].apply(lambda tags: [tag for tag in tags if tag in first_200_tags])\n",
    "\n",
    "filtered_corpus_tag_df['len_tags_in_top200'] = filtered_corpus_tag_df['tags_in_top200'].apply(lambda x: len(x))\n",
    "missing_filtered_data = filtered_corpus_tag_df[filtered_corpus_tag_df['len_tags_in_top200'] == 0].index\n",
    "\n",
    "filtered_corpus_tag_df.drop(index=missing_filtered_data, inplace=True)\n",
    "data.drop(index=missing_filtered_data, inplace=True)\n",
    "print(f\"Observations restantes dans le coprus traité: {filtered_corpus_tag_df.shape[0]}\")\n",
    "\n",
    "corpus = filtered_corpus_tag_df['splitted_text'].to_list()\n",
    "joined_corpus = filtered_corpus_tag_df['preprocessed_text'].to_list()\n",
    "top200_tags = filtered_corpus_tag_df['tags_in_top200'].to_list()"
   ],
   "id": "45685a4f763111a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(f\"Nombre de tokens du corpus {word_dist.shape[0]}\")\n",
    "print(\"Affichage des 20 tokens les plus utilisés\")\n",
    "word_dist"
   ],
   "id": "56dc53feb10cc097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7fd0c0626498a845",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "%%time\n",
    "import pickle \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vocabulary = list(word_dist[word_dist[\"Frequency\"]>=10].index)\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
    "X = tfidf_vectorizer.fit_transform(joined_corpus)\n",
    "tfidf_data = pd.DataFrame(X.toarray(), columns=vocabulary)\n",
    "print(\"Affichage des 10 premiers posts vectorisés via le modèle de TF-IDF\")\n",
    "display(tfidf_data.head(10))\n",
    "print(f\" Nombre d'observations: {tfidf_data.shape[0]}, nombre de variables: {tfidf_data.shape[1]}\")\n",
    "\n",
    "filename_tfidf_model = 'tfidf_model.pkl'\n",
    "pickle.dump(tfidf_vectorizer, open(filename_tfidf_model, 'wb'))\n",
    "\n",
    "filename_vocabulary = \"vocabulary.pkl\"\n",
    "pickle.dump(vocabulary, open(filename_vocabulary, 'wb'))"
   ],
   "id": "95fc6685ac1de5d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time \n",
    "\n",
    "import gensim\n",
    "from gensim.models import TfidfModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim import models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models import CoherenceModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Args:\n",
    "  \n",
    "        dictionary : Gensim dictionary\n",
    "        corpus : Gensim corpus\n",
    "        texts : List of input texts\n",
    "        limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "        model_list : List of LDA topic models\n",
    "        coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    \n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                            id2word=dictionary,\n",
    "                            num_topics=num_topics, \n",
    "                            random_state=42,\n",
    "                            passes=10,\n",
    "                            workers=7)\n",
    "\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "data = pd.read_pickle(\"cleaned_corpus.pkl\")\n",
    "texts = data['splitted_text'].to_list()\n",
    "id2word = corpora.Dictionary(texts)\n",
    "id2word.filter_extremes()\n",
    "\n",
    "bow_corpus = [id2word.doc2bow(text) for text in texts]\n",
    "tfidf = TfidfModel(bow_corpus)\n",
    "tfidf_corpus = [tfidf[text] for text in bow_corpus]\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=tfidf_corpus, texts=texts, start=2, limit=51, step=1)\n",
    "\n",
    "\n",
    "limit=51; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ],
   "id": "de88f1a896bf8558",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "optimal_model = model_list[5]\n",
    "\n",
    "print('\\nPerplexity: ', optimal_model.log_perplexity(tfidf_corpus))\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=optimal_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=30))"
   ],
   "id": "42a637c47522a293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "original_post = data['post']\n",
    "original_cleaned_keywords = data['splitted_tags']\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=tfidf_corpus, texts=original_post)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic = pd.concat([df_dominant_topic, original_cleaned_keywords], axis=1)\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text', 'Original_keywords']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ],
   "id": "d2fb60984bc662b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "sent_topics_sorteddf = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf = pd.concat([sent_topics_sorteddf, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf"
   ],
   "id": "94c44508419f0a96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = sent_topics_sorteddf[[\"Topic_Num\",\"Keywords\"]]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics_prop = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics_prop.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics_prop"
   ],
   "id": "f6072b83ad6eba46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# from IPython.display import HTML\n",
    "# css_str = '<style> \\\n",
    "# .jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    "# .bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    "# .jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "# text.terms { fill: #616161;} \\\n",
    "# </style>'\n",
    "# display(HTML(css_str))\n",
    "# \n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models  # don't skip this\n",
    "# import matplotlib.pyplot as plt\n",
    "# # %matplotlib inline\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim_models.prepare(optimal_model, tfidf_corpus, id2word)\n",
    "# pyLDAvis.save_html(vis, 'lda_tfidf.html')\n",
    "# display(HTML('lda_tfidf.html'))"
   ],
   "id": "68b06a4e6299eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "approche non supervisé",
   "id": "7b6dbd9c96f647eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4ecda7a39c313eff"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "lda_model = optimal_model\n",
    "def predict_unsupervised_tags(text):\n",
    "    \"\"\"\n",
    "    Predict tags of a preprocessed text\n",
    "    \n",
    "    Args:\n",
    "        text(list): preprocessed text\n",
    "        \n",
    "    Returns:\n",
    "        relevant_tags(list): list of tags\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus_new = id2word.doc2bow(text)\n",
    "    topics = lda_model.get_document_topics(corpus_new)\n",
    "    \n",
    "    #find most relevant topic according to probability\n",
    "    relevant_topic = topics[0][0]\n",
    "    relevant_topic_prob = topics[0][1]\n",
    "    \n",
    "    for i in range(len(topics)):\n",
    "        if topics[i][1] > relevant_topic_prob:\n",
    "            relevant_topic = topics[i][0]\n",
    "            relevant_topic_prob = topics[i][1]\n",
    "            \n",
    "    #retrieve associated to topic tags present in submited text\n",
    "    potential_tags = lda_model.get_topic_terms(topicid=relevant_topic, topn=20)\n",
    "    \n",
    "    relevant_tags = [id2word[tag[0]] for tag in potential_tags if id2word[tag[0]] in text]\n",
    "    \n",
    "    return relevant_tags"
   ],
   "id": "68cf49c990df6231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in range(10):\n",
    "   print(filtered_tokenized_vs_original.loc[i,'post'])\n",
    "   print(predict_unsupervised_tags(filtered_tokenized_vs_original.loc[i,'splitted_text']))\n",
    "   "
   ],
   "id": "1048db30cb8bd499",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "approche supervisé\n",
   "id": "cb5dd17d0a529ab7"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "dedup_tags = []\n",
    "for tags in top200_tags:\n",
    "    dedup_tags.append(set(tags))\n",
    "\n",
    "print('Affichage de la première occurence de dedup_tags')\n",
    "display(dedup_tags[0])"
   ],
   "id": "8c4b73579fbc15f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_data, dedup_tags, test_size=0.2, random_state=42)"
   ],
   "id": "20dcd8f3d7ef23ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(random_state=42)\n",
    "pca.fit(X_train)\n",
    "\n",
    "def display_scree_plot(pca):\n",
    "    scree = pca.explained_variance_ratio_*100\n",
    "    plt.bar(np.arange(len(scree))+1, scree)\n",
    "    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c=\"red\",marker='o')\n",
    "    plt.xlabel(\"rang de l'axe d'inertie\")\n",
    "    plt.ylabel(\"pourcentage d'inertie\")\n",
    "    plt.title(\"Eboulis des valeurs propres\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "display_scree_plot(pca)"
   ],
   "id": "c89346b41c813c7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle \n",
    "\n",
    "pca = PCA(n_components=0.85, random_state=42)\n",
    "pca.fit(X_train)\n",
    "X_train_transformed = pca.transform(X_train)\n",
    "X_test_transformed = pca.transform(X_test)\n",
    "print(f\"Nombre de composantes principales: {pca.components_.shape[0]}\")\n",
    "\n",
    "filename_pca_model = './models/pca_model.pkl'\n",
    "pickle.dump(pca, open(filename_pca_model, 'wb'))"
   ],
   "id": "ed4570ebd52876c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pickle \n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=first_200_tags)\n",
    "train_labels = mlb.fit_transform(y_train)\n",
    "test_labels = mlb.transform(y_test)\n",
    "\n",
    "print(\"Affichage des classes du modèle de vectorisation\")\n",
    "display(mlb.classes_)\n",
    "\n",
    "filename_mlb_model = './models/mlb_model.pkl'\n",
    "pickle.dump(mlb, open(filename_mlb_model,'wb'))"
   ],
   "id": "58f465f3537b27e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, hamming_loss\n",
    "\n",
    "models_performance = {}\n",
    "\n",
    "def metrics_report(model_name, test_labels, predictions, performances):\n",
    "    \"\"\"\n",
    "    Compute performance metrics of a model and store them in a dictionary\n",
    "    \n",
    "    Args:\n",
    "        model_name(string): name of the evaluated model\n",
    "        test_labels(array): labels related to predictors\n",
    "        preductions(array): predicted results\n",
    "        performances(dict): used dictionary to store metrics\n",
    "    Returns:\n",
    "        performances(dict): used dictionary to store metrics filed with models ones\n",
    "    \"\"\"    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    macro_precision = precision_score(test_labels, predictions, average='macro')\n",
    "    macro_recall = recall_score(test_labels, predictions, average='macro')\n",
    "    macro_f1 = f1_score(test_labels, predictions, average='macro')\n",
    "    micro_precision = precision_score(test_labels, predictions, average='micro')\n",
    "    micro_recall = recall_score(test_labels, predictions, average='micro')\n",
    "    micro_f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    hamLoss = hamming_loss(test_labels, predictions)\n",
    "    print(\"------\" + model_name + \" Model Metrics-----\")\n",
    "    print(\"Accuracy: {:.4f}\\nHamming Loss: {:.4f}\\nPrecision:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nRecall:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\\nF1-measure:\\n  - Macro: {:.4f}\\n  - Micro: {:.4f}\"\\\n",
    "          .format(accuracy, hamLoss, macro_precision, micro_precision, macro_recall, micro_recall, macro_f1, micro_f1))\n",
    "    \n",
    "    performances[model_name] = {}\n",
    "    performances[model_name][\"micro_precision\"] =  micro_precision\n",
    "    performances[model_name][\"micro_recall\"] = micro_recall\n",
    "    performances[model_name][\"micro_f1\"] = micro_f1\n",
    "    \n",
    "    return performances"
   ],
   "id": "53f0d3798a33dcf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train_transformed, train_labels)\n",
    "knn_predictions = knn_clf.predict(X_test_transformed)\n",
    "metrics_report(\"knn\", test_labels, knn_predictions, models_performance)"
   ],
   "id": "bf8ba05465bc460c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "svm_clf = OneVsRestClassifier(LinearSVC(), n_jobs=-1)\n",
    "svm_clf.fit(X_train_transformed, train_labels)\n",
    "\n",
    "svm_preds = svm_clf.predict(X_test_transformed)\n",
    "metrics_report(\"svm\", test_labels, svm_preds, models_performance)"
   ],
   "id": "3d7e49b8d6d624e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_jobs=-1)\n",
    "rf_clf.fit(X_train_transformed, train_labels)\n",
    "rf_preds = rf_clf.predict(X_test_transformed)\n",
    "metrics_report(\"Random Forest\", test_labels, rf_preds, models_performance)"
   ],
   "id": "96d68ab25542dd0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "gb_clf = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "gb_clf.fit(X_train_transformed, train_labels)\n",
    "gb_preds = gb_clf.predict(X_test_transformed)\n",
    "metrics_report(\"Gradient Boosting\", test_labels, gb_preds, models_performance)"
   ],
   "id": "9afeab663447f6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "result_df = pd.DataFrame.from_dict(models_performance, orient=\"index\")\n",
    "result_df"
   ],
   "id": "50744c7475d599a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "filename_svm_model = './models/svm_model.pkl'\n",
    "pickle.dump(svm_clf, open(filename_svm_model,'wb'))"
   ],
   "id": "b23e335d5bd58b14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fonction de prediction",
   "id": "31422441050422fe"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "def predict_supervised_tags(supervised_model, mlb_model, text):\n",
    "    \"\"\"\n",
    "    Predict tags according to a lemmatized text using a supervied model.\n",
    "    \n",
    "    Args:\n",
    "        supervised_model(): Used mode to get prediction\n",
    "        mlb_model(): Used model to detransform\n",
    "    Returns:\n",
    "        res(list): List of predicted tags\n",
    "    \"\"\"\n",
    "    res = tfidf_vectorizer.transform(text)\n",
    "    res = pd.DataFrame(res.toarray(), columns=vocabulary)\n",
    "    res = pca.transform(res)\n",
    "    res = supervised_model.predict(res)\n",
    "    res = mlb.inverse_transform(res)\n",
    "    res = list({tag for tag_list in res for tag in tag_list if (len(tag_list) != 0)})\n",
    "    res = [tag for tag  in res if tag in text]\n",
    "    \n",
    "    return res"
   ],
   "id": "7051cbdd92ded290",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fonction de vérification",
   "id": "b06cb4288c78fdf4"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def check_tag_predction(original_text, original_tags, preprocessed_text, supervised_model):\n",
    "    \"\"\"\n",
    "    Check original tags vs predicted tags for a post.\n",
    "\n",
    "    Args:\n",
    "        post(list) : original text\n",
    "        original_tags(list) : preprocessed_tags\n",
    "    \"\"\"\n",
    "\n",
    "    predicted_supervised_tags = predict_supervised_tags(supervised_model, mlb, preprocessed_text)\n",
    "    predicted_unsupervised_tags = predict_unsupervised_tags(preprocessed_text)\n",
    "    print(\"Publication originale: \\n\")\n",
    "    print(f\"{original_text}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags pré-traités utilisés par l'utilisateur: {original_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle supervisé: {predicted_supervised_tags}\")\n",
    "    print(\"\\n\")\n",
    "    print(f\"Liste des tags prédits par le modèle non supervisé: {predicted_unsupervised_tags}\")\n",
    "\n",
    "print(\"Test des 10 premiers documents du corpus\\n\")\n",
    "for i in range(10):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(\"\\n\")\n",
    "    check_tag_predction(filtered_tokenized_vs_original.loc[i,'Post'], \n",
    "                    filtered_tokenized_vs_original.loc[i,'splitted_tags'],\n",
    "                    filtered_tokenized_vs_original.loc[i,'splitted_text'],\n",
    "                    svm_clf)\n",
    "    print(\"-\"*100 + \"\\n\")"
   ],
   "id": "4ff38ab440600975",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle \n",
    "\n",
    "filename_model = './models/lda_model.pkl'\n",
    "pickle.dump(lda_model, open(filename_model,'wb'))\n",
    "\n",
    "filename_dictionary = './models/dictionary.pkl'\n",
    "pickle.dump(id2word, open(filename_dictionary,'wb'))"
   ],
   "id": "4dca21b23c926307",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
